<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-post-page plugin-blog plugin-id-default" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.7.0">
<title data-rh="true">DeAgent Development Log 1 | DeagentAI blog</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://blog.deagent.ai/blog/dev-log-1"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docusaurus_tag" content="default"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docsearch:docusaurus_tag" content="default"><meta data-rh="true" property="og:title" content="DeAgent Development Log 1 | DeagentAI blog"><meta data-rh="true" name="description" content="Currently, large models generally lack deep reasoning capabilities in the Web3 domain. In the DeAgent framework, the large model plays the most crucial role in the Lobe function. Most teams address this issue by either using RAG (Retrieval-Augmented Generation) or adding Web3 data during the fine-tuning phase. However, these methods do not significantly enhance the Lobe&#x27;s trading and decision-making abilities in the Web3 space."><meta data-rh="true" property="og:description" content="Currently, large models generally lack deep reasoning capabilities in the Web3 domain. In the DeAgent framework, the large model plays the most crucial role in the Lobe function. Most teams address this issue by either using RAG (Retrieval-Augmented Generation) or adding Web3 data during the fine-tuning phase. However, these methods do not significantly enhance the Lobe&#x27;s trading and decision-making abilities in the Web3 space."><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2025-02-15T00:00:00.000Z"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://blog.deagent.ai/blog/dev-log-1"><link data-rh="true" rel="alternate" href="https://blog.deagent.ai/blog/dev-log-1" hreflang="en"><link data-rh="true" rel="alternate" href="https://blog.deagent.ai/blog/dev-log-1" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","@id":"https://blog.deagent.ai/blog/dev-log-1","mainEntityOfPage":"https://blog.deagent.ai/blog/dev-log-1","url":"https://blog.deagent.ai/blog/dev-log-1","headline":"DeAgent Development Log 1","name":"DeAgent Development Log 1","description":"Currently, large models generally lack deep reasoning capabilities in the Web3 domain. In the DeAgent framework, the large model plays the most crucial role in the Lobe function. Most teams address this issue by either using RAG (Retrieval-Augmented Generation) or adding Web3 data during the fine-tuning phase. However, these methods do not significantly enhance the Lobe's trading and decision-making abilities in the Web3 space.","datePublished":"2025-02-15T00:00:00.000Z","author":[],"keywords":[],"isPartOf":{"@type":"Blog","@id":"https://blog.deagent.ai/blog","name":"Blog"}}</script><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="DeagentAI blog RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="DeagentAI blog Atom Feed"><link rel="stylesheet" href="/assets/css/styles.87056ce2.css">
<script src="/assets/js/runtime~main.214d8ea2.js" defer="defer"></script>
<script src="/assets/js/main.1e401902.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/img/logo.svg"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="DeagentAI Logo" class="themedComponent_mlkZ themedComponent--light_NVdE" style="height:28px"><img src="/img/logo.svg" alt="DeagentAI Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU" style="height:28px"></div></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/blog">Blog</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/deagentAI/deagentAI.github.io" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite" aria-pressed="false"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_re4s thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_pO2u margin-bottom--md">Recent posts</div><div role="group"><h3 class="yearGroupHeading_rMGB">2025</h3><ul class="sidebarItemList_Yudw clean-list"><li class="sidebarItem__DBe"><a aria-current="page" class="sidebarItemLink_mo7H sidebarItemLinkActive_I1ZP" href="/blog/dev-log-1">DeAgent Development Log 1</a></li></ul></div></nav></aside><main class="col col--7"><article class=""><header><h1 class="title_f1Hy">DeAgent Development Log 1</h1><div class="container_mt6G margin-vert--md"><time datetime="2025-02-15T00:00:00.000Z">February 15, 2025</time> · <!-- -->6 min read</div></header><div id="__blog-post-container" class="markdown"><p>Currently, large models generally lack deep reasoning capabilities in the Web3 domain. In the DeAgent framework, the large model plays the most crucial role in the Lobe function. Most teams address this issue by either using RAG (Retrieval-Augmented Generation) or adding Web3 data during the fine-tuning phase. However, these methods do not significantly enhance the Lobe&#x27;s trading and decision-making abilities in the Web3 space.
To solve this problem, we have designed a Web3-specific transaction Playground that integrates both Onchain and OffChain environments.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="i-data-collection">I. Data Collection<a href="#i-data-collection" class="hash-link" aria-label="Direct link to I. Data Collection" title="Direct link to I. Data Collection">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="1-on-chain-data">(1) On-chain Data<a href="#1-on-chain-data" class="hash-link" aria-label="Direct link to (1) On-chain Data" title="Direct link to (1) On-chain Data">​</a></h3>
<p><strong>1. Mainstream Token Transaction Data Domain</strong></p>
<ul>
<li><strong>Data Sources</strong>: Obtain transaction data for mainstream tokens (e.g., BTC, ETH, USDT, etc.) via blockchain explorers (such as Etherscan).</li>
<li><strong>Data Content</strong>: Includes transaction amount, transaction time, transaction addresses, transaction hash, gas fees, etc. For instance, for BTC, collect hourly transaction data for the past five years, including input/output addresses and amounts for each transaction.</li>
<li><strong>Data Format</strong>: Stored in CSV or JSON format, with fields such as - timestamp, transaction hash, sender address, receiver address, transaction amount, transaction type (regular transaction / contract transaction).</li>
</ul>
<p><strong>2. Key Moments Macro Data</strong></p>
<ul>
<li><strong>Data Sources</strong>: Gather macro data on key moments from major blockchain-related news outlets (e.g., CoinDesk, Coindance) and social media platforms (e.g., Twitter). For example, collect relevant reports during Ethereum&#x27;s successful merge event.</li>
<li><strong>Data Content</strong>: Includes descriptions of key events, occurrence time, relevant influencing factors, etc. For example, the market reaction before and after Ethereum&#x27;s merge or the impact of policy changes on the cryptocurrency market.</li>
<li><strong>Data Format</strong>: Text files storing event descriptions, with fields including event ID, event description, occurrence time, involved tokens, event type (e.g., technical upgrade, policy release).</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="2-off-chain-data">(2) Off-chain Data<a href="#2-off-chain-data" class="hash-link" aria-label="Direct link to (2) Off-chain Data" title="Direct link to (2) Off-chain Data">​</a></h3>
<p><strong>1. Hot Project Meme Twitter Data Domain</strong></p>
<ul>
<li><strong>Data Sources</strong>: Use Twitter API to collect tweets related to popular Web3 projects.</li>
<li><strong>Data Content</strong>: Includes tweet publish time, user ID, tweet content, retweets, likes, replies, etc. For instance, when a new version of Uniswap is released, gather discussions about the new features from users.</li>
<li><strong>Data Format</strong>: Stored in JSON format, with fields including tweet ID, user ID, publish time, tweet content, retweets, likes, replies.</li>
</ul>
<p><strong>2. Data of Moments with Obvious Volatility Domain</strong></p>
<ul>
<li><strong>Data Sources</strong>: Use financial data APIs (e.g., CoinGecko, Binance API) to collect data for tokens with notable popularity and high trading volume during moments of volatility.</li>
<li><strong>Data Content</strong>: Includes price fluctuations, trading volume changes, transaction prices, transaction times, and trade direction. For instance, during a market crash, track Bitcoin&#x27;s price movement from the high to the low.</li>
<li><strong>Data Format</strong>: Stored in CSV format, with fields including - timestamp, token name, price, trading volume, 24-hour price change.</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="ii-model-training">II. Model Training<a href="#ii-model-training" class="hash-link" aria-label="Direct link to II. Model Training" title="Direct link to II. Model Training">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="1-format-training">(1) Format Training<a href="#1-format-training" class="hash-link" aria-label="Direct link to (1) Format Training" title="Direct link to (1) Format Training">​</a></h3>
<p><strong>1. Step-by-Step Thinking Training Domain</strong></p>
<ul>
<li><strong>Training Data Construction</strong>: Organize the collected data into training samples in a specific format. For example, construct samples in the following format:<!-- -->
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">&lt;observations&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Current BTC price is $40,000</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">The Federal Reserve has announced a 50 basis point interest rate hike</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;/observations&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;thinking&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">The Federal Reserve&#x27;s interest rate hike could cause funds to flow out of risk assets, potentially leading to a significant negative impact on Bitcoin&#x27;s short-term price. However, in the long run, the market may gradually absorb this news, and Bitcoin&#x27;s price might rebound.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;/thinking&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;action&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Buy 30%</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;/action&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;observations&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">The current BTC price has dropped to $38,000, and trading volume has surged</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;/observations&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;thinking&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Despite the price drop, historical data suggests that within 24-48 hours after the interest rate hike announcement, it is often an opportune time to increase Bitcoin positions.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;/thinking&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;action&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Buy 50%</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;/action&gt;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
</li>
<li><strong>Training Process</strong>: Use deepseek V3 or other pre-trained large models as the base model. Input the above-formatted data into the model for supervised fine-tuning. The goal is to teach the model how to make step-by-step decisions based on observed market information and produce corresponding actions (e.g., Buy/Sell).</li>
</ul>
<p><strong>2. Horizon Expansion Training Domain</strong></p>
<ul>
<li><strong>Gradual Time Window Expansion</strong>: Gradually increase the time window of observed data during the training process. For example, start by training the model to make decisions based on only 1 hour of past data, then gradually expand to data from 1 day or 1 week.</li>
<li><strong>Multi-Time Scale Integration</strong>: Integrate decisions made by the model over different time windows, allowing the model to consider both short-term and long-term market trends.</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="2-trajectory-collection-and-prms--orm-training">(2) Trajectory Collection and PRMs &amp; ORM Training<a href="#2-trajectory-collection-and-prms--orm-training" class="hash-link" aria-label="Direct link to (2) Trajectory Collection and PRMs &amp; ORM Training" title="Direct link to (2) Trajectory Collection and PRMs &amp; ORM Training">​</a></h3>
<p><strong>1. Trajectory Collection Domain</strong></p>
<ul>
<li><strong>Data Structured Storage</strong>: During interactions between the model and the Playground environment, store the model&#x27;s thought process, observed data, and actions taken in a trajectory database. For example:<!-- -->
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">timestamp: 2024-10-01 09:00:00</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">observations: [{&quot;BTC price&quot;: 38000, &quot;News&quot;: &quot;SEC announcement&quot;}, ...]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">thinking: &quot;Based on the SEC news release time and historical price behavior, I need to further analyze market reactions&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">action: {&quot;buy&quot;: 0.3}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">next_observations: [{&quot;BTC price&quot;: 37800, &quot;Volume&quot;: 10000}, ...]</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
</li>
<li><strong>Trajectory Multi-Angle Analysis</strong>: Perform multi-dimensional analysis on the collected trajectories, such as the relationship between actions and returns, and the relationship between thinking processes and decision quality.</li>
</ul>
<p><strong>2. PRMs Training Domain</strong></p>
<ul>
<li><strong>Designing the Reward Function</strong>: Based on trajectory data, design a process-based reward model (PRMs). For example, set reward weights for the following parameters:<!-- -->
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">profit_loss_weight = 0.6</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">thinking_rationality_weight = 0.4</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">risk_weight = 0.2</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
</li>
<li><strong>Optimizing Reward Model Parameters</strong>: Continuously optimize the reward model parameters using reinforcement learning algorithms (e.g., PPO).</li>
</ul>
<p><strong>3. ORM Training Domain</strong></p>
<ul>
<li><strong>Online Reinforcement Learning Integration</strong>: Dynamically combine reinforcement learning algorithms with trajectory data.</li>
<li><strong>Memory Optimization Strategy</strong>: Optimize the model&#x27;s memory mechanism to improve its ability to recall past decision-making experiences.</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="iii-evaluation--optimization">III. Evaluation &amp; Optimization<a href="#iii-evaluation--optimization" class="hash-link" aria-label="Direct link to III. Evaluation &amp; Optimization" title="Direct link to III. Evaluation &amp; Optimization">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="1-evaluation-metrics-domain">(1) Evaluation Metrics Domain<a href="#1-evaluation-metrics-domain" class="hash-link" aria-label="Direct link to (1) Evaluation Metrics Domain" title="Direct link to (1) Evaluation Metrics Domain">​</a></h3>
<p><strong>1. Trading Profitability Domain</strong></p>
<ul>
<li><strong>Profit Calculation</strong>: Calculate the total profit of the model&#x27;s simulated trading in the Playground environment.</li>
<li><strong>Sharpe Ratio</strong>: Measure the risk-adjusted return. The formula is: Sharpe Ratio=(Return−Risk-Free Rate)/Standard Deviation.</li>
</ul>
<p><strong>2. Reasoning Accuracy Domain</strong></p>
<ul>
<li><strong>Thinking Process Quality Rating</strong>: Invite financial experts to rate the model&#x27;s reasoning process based on criteria such as logical coherence and completeness of factors covered.</li>
<li><strong>Action-Decision Consistency</strong>: Analyze the consistency between the model&#x27;s actions and its thought process.</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="2-optimization-methods-domain">(2) Optimization Methods Domain<a href="#2-optimization-methods-domain" class="hash-link" aria-label="Direct link to (2) Optimization Methods Domain" title="Direct link to (2) Optimization Methods Domain">​</a></h3>
<p><strong>1. Weight Adjustment Domain</strong></p>
<ul>
<li><strong>Fine-tuning Model Weights</strong>: Based on evaluation results, fine-tune the weights of various layers in the model.</li>
<li><strong>Transfer Learning</strong>: Transfer knowledge from models trained in other domains to the Web3 trading decision model.</li>
</ul>
<p><strong>2. Reward Function Modification Domain</strong></p>
<ul>
<li><strong>Adding Multiple Reward Factors</strong>: Adjust the reward function to include additional influencing factors, such as market liquidity and policy risks.</li>
<li><strong>Dynamic Reward Adjustment</strong>: Dynamically adjust the reward function parameters based on market volatility.</li>
</ul>
<p>Through these experimental approaches, we aim to systematically enhance the large model&#x27;s trading and decision-making capabilities in the Web3 domain.</p></div></article></main><div class="col col--2"><div class="tableOfContents_bqdL thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#i-data-collection" class="table-of-contents__link toc-highlight">I. Data Collection</a><ul><li><a href="#1-on-chain-data" class="table-of-contents__link toc-highlight">(1) On-chain Data</a></li><li><a href="#2-off-chain-data" class="table-of-contents__link toc-highlight">(2) Off-chain Data</a></li></ul></li><li><a href="#ii-model-training" class="table-of-contents__link toc-highlight">II. Model Training</a><ul><li><a href="#1-format-training" class="table-of-contents__link toc-highlight">(1) Format Training</a></li><li><a href="#2-trajectory-collection-and-prms--orm-training" class="table-of-contents__link toc-highlight">(2) Trajectory Collection and PRMs &amp; ORM Training</a></li></ul></li><li><a href="#iii-evaluation--optimization" class="table-of-contents__link toc-highlight">III. Evaluation &amp; Optimization</a><ul><li><a href="#1-evaluation-metrics-domain" class="table-of-contents__link toc-highlight">(1) Evaluation Metrics Domain</a></li><li><a href="#2-optimization-methods-domain" class="table-of-contents__link toc-highlight">(2) Optimization Methods Domain</a></li></ul></li></ul></div></div></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/blog">Blog</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://discord.com/invite/deagentai" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://x.com/deagentai" target="_blank" rel="noopener noreferrer" class="footer__link-item">X<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/deagentAI/deagentAI.github.io" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 DeagentAI blog</div></div></div></footer></div>
</body>
</html>